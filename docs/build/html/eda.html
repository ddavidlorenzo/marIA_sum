<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Exploratory Data Analysis of the XL-Sum dataset. &mdash; Implementation of a framework to fine-tune GPT/GPT2 based models on abstractive summarization.  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="GPT2Summarizer (gpt2_summarizer.py)" href="code.html" />
    <link rel="prev" title="Introduction" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Implementation of a framework to fine-tune GPT/GPT2 based models on abstractive summarization.
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Exploratory Data Analysis of the <em>XL-Sum</em> dataset.</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Preliminary-data-analysis">Preliminary data analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Impact-of-the-limited-dimensionality-of-the-Language-Models-for-Abstractive-Summarization">Impact of the limited dimensionality of the Language Models for Abstractive Summarization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Training-set">Training set</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Validation-set">Validation set</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Test-set">Test set</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Recap">Recap</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="code.html">GPT2Summarizer (<code class="docutils literal notranslate"><span class="pre">gpt2_summarizer.py</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-gpt2_summarizer_train">TrainGPT2Summarizer (<code class="docutils literal notranslate"><span class="pre">gpt2_summarizer_train.py</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-utils">Utils (<code class="docutils literal notranslate"><span class="pre">utils.py</span></code>)</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Implementation of a framework to fine-tune GPT/GPT2 based models on abstractive summarization.</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Exploratory Data Analysis of the <em>XL-Sum</em> dataset.</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/eda.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Exploratory-Data-Analysis-of-the-XL-Sum-dataset.">
<h1>Exploratory Data Analysis of the <em>XL-Sum</em> dataset.<a class="headerlink" href="#Exploratory-Data-Analysis-of-the-XL-Sum-dataset." title="Permalink to this headline"></a></h1>
<p><strong>As part of the MSc. dissertation: Applying large Spanish language models to Natural Language Processing tasks.</strong></p>
<p>David Lorenzo Alfaro</p>
<p>July, 2022</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">RobertaForMaskedLM</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">get_tokenized_text</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<section id="Preliminary-data-analysis">
<h2>Preliminary data analysis<a class="headerlink" href="#Preliminary-data-analysis" title="Permalink to this headline"></a></h2>
<p>Let us first load the data from disk. It is a prerrequisite to either have it downloaded locally and located in a subdirectory called <code class="docutils literal notranslate"><span class="pre">summaries/</span></code>, or make the appropriate modifications to the code to load it (e.g., via the HuggingFace’s datasets library, <code class="docutils literal notranslate"><span class="pre">wget</span></code> request/s). In particular, we gathered the data from the <em>XL-Sum</em> official <a class="reference external" href="https://github.com/csebuetnlp/xl-sum">GitHub repository</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;summaries/all&#39;</span><span class="p">)</span>
<span class="n">TRAIN_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;train.jsonl&#39;</span><span class="p">)</span>
<span class="n">VAL_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;val.jsonl&#39;</span><span class="p">)</span>
<span class="n">TEST_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;test.jsonl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The necessary columns in the dataset are as listed: * <code class="docutils literal notranslate"><span class="pre">text</span></code>: content of an article. * <code class="docutils literal notranslate"><span class="pre">summary</span></code>: summary of an article. * <code class="docutils literal notranslate"><span class="pre">id</span></code>: unique identifier of the article.</p>
<p>Indeed, other than article-summary pairs, all remaining information may be disregarded for the task that we are aimed at conducting.</p>
<p>Let us first load the training dataset to inspect some of its properties</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">TRAIN_PATH</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)[[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<p>Now, let us print the first <span class="math notranslate nohighlight">\(k\)</span> elements of the training dataset</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top_k</span><span class="o">=</span><span class="mi">3</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span><span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">df_train</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">df_train</span><span class="o">.</span><span class="n">text</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">top_k</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;id:</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="se">\n</span><span class="s1">Text: </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">Summary: </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
id:140930_ultnot_siria_onu_comida_ch
Text: De no recibir más dinero, las raciones de la ONU en Siria se terminarán en dos meses. En un informe al Consejo de Seguridad de la ONU, Amos dijo que las raciones del PMA destinadas a los 4.000.000 de sirios ya han sido recortadas para poder llegar a la mayor cantidad de personas posible. Amos también hizo un llamado a juntar suministros para proteger a los sirios del frío, en miras al próximo invierno.
Summary: La directora de ayuda humanitaria de Naciones Unidas, Valerie Amos, advirtió que de no invertir más dinero, el Programa Mundial de Alimentos tendrá que detener sus operaciones en Siria en dos meses.

id:130809_ultnot_protesta_cachemira_protesa_aa
Text: Manifestantes hindúes gritan consignas contra el gobierno en la región de Cachemira administrada por India. Las manifestaciones tuvieron lugar después de los rezos especiales Eid, en la ciudad de Srinagar y en diversas ciudades de la región. La policía dice que la respuesta se produjo cuando la muchedumbre se volvió violenta y empezó a lanzarles palos y piedras. Varios policías y manifestantes resultaron heridos. El jueves a la noche diversos líderes separatistas fueron arrestados para evitar que lideraran las protestas.
Summary: La policía en la región de Cachemira administrada por India, lanzó gas lacrimógeno y disparó balas de goma para dispersar una protesa contra supuestas violaciones de los derechos humanos llevadas a cabo por las fuerzas del gobierno.

id:media-37220890
Text: Así lo vemos en esta animación que muestra cómo el río busca nuevos caminos. Si bien el mundo ha perdido millones de litros de agua, también se han ganado 115.000 kilómetros cuadrados. La zona donde ha habido un mayor aumento de agua en el mundo es en la meseta tibetana (donde el derretimiento de glaciares está creando lagos). Pero es en el Amazonas donde esta lucha es más evidente.
Summary: La naturaleza es un hueso duro de roer.

</pre></div></div>
</div>
<p>Alternatively, one can resort to the built-in function <code class="docutils literal notranslate"><span class="pre">head</span></code> available in <code class="docutils literal notranslate"><span class="pre">pd.DataFrame</span></code> objects.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">top_k</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>summary</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>140930_ultnot_siria_onu_comida_ch</td>
      <td>La directora de ayuda humanitaria de Naciones ...</td>
      <td>De no recibir más dinero, las raciones de la O...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>130809_ultnot_protesta_cachemira_protesa_aa</td>
      <td>La policía en la región de Cachemira administr...</td>
      <td>Manifestantes hindúes gritan consignas contra ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>media-37220890</td>
      <td>La naturaleza es un hueso duro de roer.</td>
      <td>Así lo vemos en esta animación que muestra cóm...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<section id="Impact-of-the-limited-dimensionality-of-the-Language-Models-for-Abstractive-Summarization">
<h3>Impact of the limited dimensionality of the Language Models for Abstractive Summarization<a class="headerlink" href="#Impact-of-the-limited-dimensionality-of-the-Language-Models-for-Abstractive-Summarization" title="Permalink to this headline"></a></h3>
<p>Both GPT-2 and RoBERTa work on the subword level. All spanish language models from the MarIA project have a limited dimensionality of 512 tokens (or subwords). Furthermore, in order to generate summaries on a decoder-only system, both the text and the summary must fit into the model, which imposes further restrictions on the amount of instances in the dataset that can be processed in as as-is fashion (i.e., without needing to do any further modification in the text/summary of those instances
before feeding them into the model). In summarization tasks, where the prominent practice is to strive for models with larger dimensionalities, this shortcoming is of vital relevance because it necessarily constraints the capabilities of the models to work with large texts.</p>
</section>
<section id="Training-set">
<h3>Training set<a class="headerlink" href="#Training-set" title="Permalink to this headline"></a></h3>
<p>Let us inspect the number of <em>valid</em> instances (those that fit into the model) in the training set of data, using the GPT-2 model, and a RoBERTa2RoBERTa (a.k.a. RoBERTaShared) model. To that end, we will compute the number of article and summary tokens using the GPT-2 tokenizer for the spanish LM, and the number of article tokens using the RoBERTa tokenizer. Note that there is no need to compute the per-summary no. of tokens because this model will be subsequently used as the <em>warmed-up</em> models
of an encoder-decoder system. However, we will also yield this statistic in order to further study some properties about the length of the summaries, which can be of vital relevance in the generation of the summaries.</p>
<p>Beforehand, let us define some useful functions that will enable us to comptue the number of tokens of a collection of tokens using a tokenizer (<code class="docutils literal notranslate"><span class="pre">calc_document_tokens</span></code>), and to plot histograms for article and summary length (also in terms of subwords) and a scatterplot relating these two random variables.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calc_document_tokens</span><span class="p">(</span><span class="n">documents</span><span class="p">:</span><span class="n">Iterable</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot; Compute the number of tokens of a collection of documents using a pretrained tokenizer</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    documents : Iterable</span>
<span class="sd">        Collection of documents</span>

<span class="sd">    tokenizer : Union[str, Path]</span>
<span class="sd">        Model identifier of a predefined tokenizer hosted inside a model repo</span>
<span class="sd">         on huggingface.co</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Load tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">get_tokenized_text</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">))</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">plot_stats</span><span class="p">(</span><span class="n">article_tokens</span><span class="p">:</span><span class="n">Iterable</span><span class="p">,</span> <span class="n">summary_tokens</span><span class="p">:</span><span class="n">Iterable</span><span class="p">,</span> <span class="n">hist_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">scatter_marker_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Plot some statistics about the article and summary tokens.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    article_tokens : Iterable</span>
<span class="sd">        Collection of per-sample article tokens</span>

<span class="sd">    summary_tokens : Iterable</span>
<span class="sd">        Collection of per-sample summary tokens</span>

<span class="sd">    hist_bins : int</span>
<span class="sd">        Number of bins used to discretize data for histograms, defaults to 20</span>

<span class="sd">    scatter_marker_size : int</span>
<span class="sd">        Marker size of the scatter-plot, defaults to 3</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">article_tokens</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">hist_bins</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">summary_tokens</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">hist_bins</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">article_tokens</span><span class="p">,</span> <span class="n">summary_tokens</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">scatter_marker_size</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Now, let us compute the of tokens for the articles and summaries using the tokenizers of the GPT-2 and RoBERTa checkpoints.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoint_gpt2</span> <span class="o">=</span> <span class="s2">&quot;PlanTL-GOB-ES/gpt2-base-bne&quot;</span>
<span class="n">gpt2_article_tokens_train</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">checkpoint_gpt2</span><span class="p">)</span>
<span class="n">gpt2_summary_tokens_train</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">checkpoint_gpt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoint_roberta</span> <span class="o">=</span> <span class="s2">&quot;PlanTL-GOB-ES/roberta-base-bne&quot;</span>
<span class="n">roberta_article_tokens_train</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">checkpoint_roberta</span><span class="p">)</span>
<span class="n">roberta_summary_tokens_train</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">checkpoint_roberta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Token indices sequence length is longer than the specified maximum sequence length for this model (2183 &gt; 512). Running this sequence through the model will result in indexing errors
</pre></div></div>
</div>
<p>To perform fine-tuning on a GPT-2 based model, at least 1 token should be reserved for a special token, which will serve as a separator between the article and the summary of each input sample. As you may see from the training sources, our particular take is to use the <code class="docutils literal notranslate"><span class="pre">&lt;|sep|&gt;</span></code> gram as the separator token, albeit a different sequence may be used, so long it does not conflict with an existing entry in the vocabulary of the tokenizer.</p>
<p>On the other hand, although we that the input maximum length is constraint to 512 tokens, a programmatic way to check such limitation is by accessing to the <code class="docutils literal notranslate"><span class="pre">config.n_positions</span></code> property of a GPT-2 HuggingFace checkpoint.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpt2_max_n_tokens</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_gpt2</span><span class="p">)</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_positions</span>
<span class="n">gpt2_valid_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">gpt2_max_n_tokens</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens_train</span><span class="p">,</span><span class="n">gpt2_summary_tokens_train</span><span class="p">))))</span>
<span class="n">gpt2_invalid_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpt2_article_tokens_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">gpt2_valid_train</span>
<span class="c1"># out of the box... how many articles can be processed by the gpt-2 model?</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using the &quot;</span><span class="si">{</span><span class="n">checkpoint_gpt2</span><span class="si">}</span><span class="s1">&quot; model, </span><span class="si">{</span><span class="n">gpt2_valid_train</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">gpt2_article_tokens_train</span><span class="p">)</span><span class="si">}</span><span class="s1"> training samples have &lt;= </span><span class="si">{</span><span class="n">gpt2_max_n_tokens</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1"> tokens and thus are subject to application out of the box, whereas </span><span class="si">{</span><span class="n">gpt2_invalid_train</span><span class="si">}</span><span class="s1"> will cause an error unless further measures are taken (e.g., via truncation of info. in a meaningful fashion).&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using the &#34;PlanTL-GOB-ES/gpt2-base-bne&#34; model, 9692 out of 38110 training samples have &lt;= 511 tokens and thus are subject to application out of the box, whereas 28418 will cause an error unless further measures are taken (e.g., via truncation of info. in a meaningful fashion).
</pre></div></div>
</div>
<p>Let us further inspect some properties about the samples in the training dataset: * How are the length of the articles and summaries distributed? * Are the length of the article and its summary correlated?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_stats</span><span class="p">(</span><span class="n">gpt2_article_tokens_train</span><span class="p">,</span> <span class="n">gpt2_summary_tokens_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/eda_22_0.png" src="_images/eda_22_0.png" />
</div>
</div>
<p>From the graphs we can tell: * vast majority of the articles are around 500 to 1500 tokens long, whereas regular summary length revolves around 20 to 50 tokens. * summary length seems to be independent from the length of the article.</p>
<p>We can also calculate some descriptive statistics summarizing the central tendency, dispersion and shape of the distribution of the article and summary tokens.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[68]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens_train</span><span class="p">,</span><span class="n">gpt2_summary_tokens_train</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gpt2_article_tokens_train&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt2_summary_tokens_train&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[68]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpt2_article_tokens_train</th>
      <th>gpt2_summary_tokens_train</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>38110.000000</td>
      <td>38110.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1034.331068</td>
      <td>34.986119</td>
    </tr>
    <tr>
      <th>std</th>
      <td>769.745530</td>
      <td>14.608020</td>
    </tr>
    <tr>
      <th>min</th>
      <td>31.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>466.000000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>956.000000</td>
      <td>34.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1415.000000</td>
      <td>43.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>12421.000000</td>
      <td>216.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Conclusions: * Mean number of article tokens in the training set: <span class="math notranslate nohighlight">\(1034\pm770\)</span>. 770 is a large standard deviation, hence the mean is not a very informative statistic (e.g., because of the influence of extreme values). The median may be more useful: <span class="math notranslate nohighlight">\(956\)</span> tokens.</p>
<ul class="simple">
<li><p>Mean number of summary tokens in the training set: <span class="math notranslate nohighlight">\(35\pm15\)</span>. The value of the median is very similar: <span class="math notranslate nohighlight">\(34\)</span>.</p></li>
</ul>
<p>Let us do the same for the RoBERTa LM, considering that the maximum number of tokens that the model can handle is two less than that reported of the model, being as we need to reserve two extra positions (or segments) for two special tokens. To double-check the maximum input of the length we can access to the <code class="docutils literal notranslate"><span class="pre">config.max_position_embeddings</span></code> property of the RoBERTa HuggingFace checkpoint.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roberta</span> <span class="o">=</span> <span class="n">RobertaForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_roberta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roberta_max_n_tokens</span> <span class="o">=</span> <span class="n">RobertaForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_roberta</span><span class="p">)</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">-</span> <span class="mi">2</span> <span class="c1"># reserve tokens for [CLS] and [EOS]</span>
<span class="n">roberta_valid_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">&lt;=</span><span class="n">roberta_max_n_tokens</span><span class="p">,</span> <span class="n">roberta_article_tokens_train</span><span class="p">)))</span>
<span class="n">roberta_invalid_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">roberta_article_tokens_train</span><span class="p">)</span> <span class="o">-</span> <span class="n">roberta_valid_train</span>
<span class="c1"># out of the box... how many articles can be processed by the roberta model?</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using the &quot;</span><span class="si">{</span><span class="n">checkpoint_roberta</span><span class="si">}</span><span class="s1">&quot; model, </span><span class="si">{</span><span class="n">roberta_valid_train</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">roberta_article_tokens_train</span><span class="p">)</span><span class="si">}</span><span class="s1"> training samples have &lt;= </span><span class="si">{</span><span class="n">roberta_max_n_tokens</span><span class="si">}</span><span class="s1"> tokens and thus are subject to application out of the box, whereas </span><span class="si">{</span><span class="n">roberta_invalid_train</span><span class="si">}</span><span class="s1"> will cause an error unless further measures are taken (e.g., via truncation of info. in a meaningful fashion).&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using the &#34;PlanTL-GOB-ES/roberta-base-bne&#34; model, 10235 out of 38110 training samples have &lt;= 512 tokens and thus are subject to application out of the box, whereas 27875 will cause an error unless further measures are taken (e.g., via truncation of info. in a meaningful fashion).
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_stats</span><span class="p">(</span><span class="n">roberta_article_tokens_train</span><span class="p">,</span> <span class="n">roberta_summary_tokens_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/eda_29_0.png" src="_images/eda_29_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[69]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">roberta_article_tokens_train</span><span class="p">,</span><span class="n">roberta_summary_tokens_train</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;roberta_article_tokens_train&quot;</span><span class="p">,</span> <span class="s2">&quot;roberta_summary_tokens_train&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[69]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>roberta_article_tokens_train</th>
      <th>roberta_summary_tokens_train</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>38110.000000</td>
      <td>38110.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1035.331068</td>
      <td>35.986119</td>
    </tr>
    <tr>
      <th>std</th>
      <td>769.745530</td>
      <td>14.608020</td>
    </tr>
    <tr>
      <th>min</th>
      <td>32.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>467.000000</td>
      <td>26.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>957.000000</td>
      <td>35.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1416.000000</td>
      <td>44.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>12422.000000</td>
      <td>217.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Analogous conclusions can be inferred when using the RoBERTa tokenizer, with nearly negligible differences.</p>
</section>
<section id="Validation-set">
<h3>Validation set<a class="headerlink" href="#Validation-set" title="Permalink to this headline"></a></h3>
<p>Now, let us conduct this experiment on the validation and test datasets:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_val</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">VAL_PATH</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)[[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpt2_article_tokens_val</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_val</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">checkpoint_gpt2</span><span class="p">)</span>
<span class="n">gpt2_summary_tokens_val</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_val</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">checkpoint_gpt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpt2_valid_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">gpt2_max_n_tokens</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens_val</span><span class="p">,</span><span class="n">gpt2_summary_tokens_val</span><span class="p">))))</span>
<span class="n">gpt2_invalid_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpt2_article_tokens_val</span><span class="p">)</span> <span class="o">-</span> <span class="n">gpt2_valid_val</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using the &quot;</span><span class="si">{</span><span class="n">checkpoint_gpt2</span><span class="si">}</span><span class="s1">&quot; model, </span><span class="si">{</span><span class="n">gpt2_valid_val</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">gpt2_article_tokens_val</span><span class="p">)</span><span class="si">}</span><span class="s1"> validation samples have &lt;= </span><span class="si">{</span><span class="n">gpt2_max_n_tokens</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1"> tokens and thus are subject to application out of the box, whereas </span><span class="si">{</span><span class="n">gpt2_invalid_val</span><span class="si">}</span><span class="s1"> will cause an error unless further measures are taken.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using the &#34;PlanTL-GOB-ES/gpt2-base-bne&#34; model, 814 out of 4763 validation samples have &lt;= 511 tokens and thus are subject to application out of the box, whereas 3949 will cause an error unless further measures are taken.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[70]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_stats</span><span class="p">(</span><span class="n">gpt2_article_tokens_val</span><span class="p">,</span> <span class="n">gpt2_summary_tokens_val</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/eda_37_0.png" src="_images/eda_37_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[71]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens_val</span><span class="p">,</span><span class="n">gpt2_summary_tokens_val</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gpt2_article_tokens_val&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt2_summary_tokens_val&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[71]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpt2_article_tokens_val</th>
      <th>gpt2_summary_tokens_val</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>4763.000000</td>
      <td>4763.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>950.719295</td>
      <td>34.226748</td>
    </tr>
    <tr>
      <th>std</th>
      <td>446.983980</td>
      <td>11.507983</td>
    </tr>
    <tr>
      <th>min</th>
      <td>75.000000</td>
      <td>11.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>615.000000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>951.000000</td>
      <td>33.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1286.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2038.000000</td>
      <td>73.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can draw similar conclusions to those obtained for the training set: * Vast majority of the articles are around 600 to 1200 tokens long, whereas regular summary length revolves around 20 to 45 tokens. * Summary length seems to be independent from the length of the article. * Mean number of article tokens in the validation set: <span class="math notranslate nohighlight">\(950\pm447\)</span>. Fairly close to the median: <span class="math notranslate nohighlight">\(951\)</span> tokens. * Mean number of summary tokens in the validation set: <span class="math notranslate nohighlight">\(34\pm12\)</span>. The value of the median
is very similar: <span class="math notranslate nohighlight">\(33\)</span>.</p>
<p>In order to avoid verbosity, we eschew reproducing these experiments using the RoBERTa tokenizer, since very similar results are to expect.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roberta_article_tokens_val</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_val</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">checkpoint_roberta</span><span class="p">)</span>
<span class="n">roberta_summary_tokens_val</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_val</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">checkpoint_roberta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Token indices sequence length is longer than the specified maximum sequence length for this model (780 &gt; 512). Running this sequence through the model will result in indexing errors
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roberta_valid_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">&lt;=</span><span class="n">roberta_max_n_tokens</span><span class="p">,</span> <span class="n">roberta_article_tokens_val</span><span class="p">)))</span>
<span class="n">roberta_invalid_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">roberta_article_tokens_val</span><span class="p">)</span> <span class="o">-</span> <span class="n">roberta_valid_val</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using the &quot;</span><span class="si">{</span><span class="n">checkpoint_roberta</span><span class="si">}</span><span class="s1">&quot; model, </span><span class="si">{</span><span class="n">roberta_valid_val</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">roberta_article_tokens_val</span><span class="p">)</span><span class="si">}</span><span class="s1"> training samples have &lt;= </span><span class="si">{</span><span class="n">roberta_max_n_tokens</span><span class="si">}</span><span class="s1"> tokens and thus are subject to application out of the box, whereas </span><span class="si">{</span><span class="n">roberta_invalid_val</span><span class="si">}</span><span class="s1"> will cause an error unless further measures are taken.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using the &#34;PlanTL-GOB-ES/roberta-base-bne&#34; model, 903 out of 4763 training samples have &lt;= 512 tokens and thus are subject to application out of the box, whereas 3860 will cause an error unless further measures are taken.
</pre></div></div>
</div>
</section>
<section id="Test-set">
<h3>Test set<a class="headerlink" href="#Test-set" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">TEST_PATH</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)[[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpt2_article_tokens_test</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">checkpoint_gpt2</span><span class="p">)</span>
<span class="n">gpt2_summary_tokens_test</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">checkpoint_gpt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpt2_valid_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">gpt2_max_n_tokens</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens_test</span><span class="p">,</span><span class="n">gpt2_summary_tokens_test</span><span class="p">))))</span>
<span class="n">gpt2_invalid_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpt2_article_tokens_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">gpt2_valid_val</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using the &quot;</span><span class="si">{</span><span class="n">checkpoint_gpt2</span><span class="si">}</span><span class="s1">&quot; model, </span><span class="si">{</span><span class="n">gpt2_valid_test</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">gpt2_article_tokens_test</span><span class="p">)</span><span class="si">}</span><span class="s1"> test samples have &lt;= </span><span class="si">{</span><span class="n">gpt2_max_n_tokens</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1"> tokens and thus are subject to application out of the box, whereas </span><span class="si">{</span><span class="n">gpt2_invalid_test</span><span class="si">}</span><span class="s1"> will cause an error unless further measures are taken.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using the &#34;PlanTL-GOB-ES/gpt2-base-bne&#34; model, 804 out of 4763 test samples have &lt;= 511 tokens and thus are subject to application out of the box, whereas 3949 will cause an error unless further measures are taken.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[72]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_stats</span><span class="p">(</span><span class="n">gpt2_article_tokens_test</span><span class="p">,</span> <span class="n">gpt2_summary_tokens_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/eda_46_0.png" src="_images/eda_46_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[73]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens_test</span><span class="p">,</span><span class="n">gpt2_summary_tokens_test</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gpt2_article_tokens_test&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt2_summary_tokens_test&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[73]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpt2_article_tokens_test</th>
      <th>gpt2_summary_tokens_test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>4763.000000</td>
      <td>4763.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>948.605921</td>
      <td>34.231787</td>
    </tr>
    <tr>
      <th>std</th>
      <td>444.319426</td>
      <td>11.396173</td>
    </tr>
    <tr>
      <th>min</th>
      <td>75.000000</td>
      <td>11.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>616.000000</td>
      <td>26.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>951.000000</td>
      <td>33.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1283.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2002.000000</td>
      <td>73.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can draw similar conclusions to those obtained for the training and validation set, which enable us to assert that, overall, <strong>the number of article and summary tokens across the different datasets are independent and identically distributed</strong>: * Vast majority of the articles are around 600 to 1200 tokens long, whereas regular summary length revolves around 20 to 45 tokens. * Summary length seems to be independent from the length of the article. * Mean number of article tokens in the test
set: <span class="math notranslate nohighlight">\(959\pm444\)</span>. Fairly close to the median: <span class="math notranslate nohighlight">\(951\)</span> tokens. * Mean number of summary tokens in the test set: <span class="math notranslate nohighlight">\(34\pm11\)</span>. The value of the median is very similar: <span class="math notranslate nohighlight">\(33\)</span>.</p>
<p>In order to avoid verbosity, we eschew reproducing these experiments using the RoBERTa tokenizer, since very similar results are to expect.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roberta_article_tokens_test</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">checkpoint_roberta</span><span class="p">)</span>
<span class="n">roberta_summary_tokens_test</span> <span class="o">=</span> <span class="n">calc_document_tokens</span><span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">summary</span><span class="p">,</span> <span class="n">checkpoint_roberta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Token indices sequence length is longer than the specified maximum sequence length for this model (1248 &gt; 512). Running this sequence through the model will result in indexing errors
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roberta_valid_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">&lt;=</span><span class="n">roberta_max_n_tokens</span><span class="p">,</span> <span class="n">roberta_article_tokens_test</span><span class="p">)))</span>
<span class="n">roberta_invalid_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">roberta_article_tokens_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">roberta_valid_test</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using the &quot;</span><span class="si">{</span><span class="n">checkpoint_roberta</span><span class="si">}</span><span class="s1">&quot; model, </span><span class="si">{</span><span class="n">roberta_valid_test</span><span class="si">}</span><span class="s1"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">roberta_article_tokens_test</span><span class="p">)</span><span class="si">}</span><span class="s1"> training samples have &lt;= </span><span class="si">{</span><span class="n">roberta_max_n_tokens</span><span class="si">}</span><span class="s1"> tokens and thus are subject to application out of the box, whereas </span><span class="si">{</span><span class="n">roberta_invalid_test</span><span class="si">}</span><span class="s1"> will cause an error unless further measures are taken.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using the &#34;PlanTL-GOB-ES/roberta-base-bne&#34; model, 897 out of 4763 training samples have &lt;= 512 tokens and thus are subject to application out of the box, whereas 3866 will cause an error unless further measures are taken.
</pre></div></div>
</div>
</section>
</section>
<section id="Recap">
<h2>Recap<a class="headerlink" href="#Recap" title="Permalink to this headline"></a></h2>
<p>Let us bring all data together to draw the final conclusions. To that end, and considering differences between the number of subwords using the different tokenizers, we will repeat the previous process using the training, validation and test sets altogether.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[78]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpt2_article_tokens</span> <span class="o">=</span> <span class="n">gpt2_article_tokens_train</span> <span class="o">+</span> <span class="n">gpt2_article_tokens_val</span> <span class="o">+</span> <span class="n">gpt2_article_tokens_test</span>
<span class="n">gpt2_summary_tokens</span> <span class="o">=</span> <span class="n">gpt2_summary_tokens_train</span> <span class="o">+</span> <span class="n">gpt2_summary_tokens_val</span> <span class="o">+</span> <span class="n">gpt2_summary_tokens_test</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_stats</span><span class="p">(</span><span class="n">gpt2_article_tokens</span><span class="p">,</span> <span class="n">gpt2_summary_tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/eda_54_0.png" src="_images/eda_54_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[87]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_gpt2_tokens</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gpt2_article_tokens</span><span class="p">,</span><span class="n">gpt2_summary_tokens</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gpt2_article_tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt2_summary_tokens&quot;</span><span class="p">])</span>
<span class="n">df_gpt2_tokens</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[87]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpt2_article_tokens</th>
      <th>gpt2_summary_tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>47636.000000</td>
      <td>47636.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1017.399509</td>
      <td>34.834768</td>
    </tr>
    <tr>
      <th>std</th>
      <td>717.547947</td>
      <td>14.036877</td>
    </tr>
    <tr>
      <th>min</th>
      <td>31.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>506.000000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>955.000000</td>
      <td>34.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1379.000000</td>
      <td>43.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>12421.000000</td>
      <td>216.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<ul class="simple">
<li><p>Vast majority of the articles are around 500 to 1300 tokens long, whereas regular summary length revolves around 25 to 45 tokens.</p></li>
<li><p>Summary length seems to be independent from the length of the article.</p></li>
<li><p>Mean number of article tokens in the training set: <span class="math notranslate nohighlight">\(1017\pm718\)</span>. Fairly close to the median: <span class="math notranslate nohighlight">\(955\)</span> tokens.</p></li>
<li><p>Mean number of summary tokens in the training set: <span class="math notranslate nohighlight">\(35\pm14\)</span>. The value of the median is very similar: <span class="math notranslate nohighlight">\(34\)</span>.</p></li>
</ul>
<p>Some implications of these statistics is that when fine-tuning our models, no matter the data that is used to (i) train the models, (ii) validate or supervise the training process, and to (iii) assess goodness of the resulting models, if we aim at maximising performance metrics like ROUGE, one thing to bear in mind is that the summaries should have a length of around <span class="math notranslate nohighlight">\(35\pm14\)</span> tokens. This is essentially due to the fact that, even if we solely use samples that can be entirely fitted into
the model (i.e., without the need to trim/remove information from the original article and/or summary), the extent of the summary in terms of no. of subwords is independent of the size of the article. We can, indeed, double check it ourselves:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[90]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_gpt2_tokens</span><span class="p">[</span><span class="n">df_gpt2_tokens</span><span class="o">.</span><span class="n">gpt2_article_tokens</span> <span class="o">&lt;=</span> <span class="n">gpt2_max_n_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[90]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gpt2_article_tokens</th>
      <th>gpt2_summary_tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>12063.000000</td>
      <td>12063.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>231.739120</td>
      <td>34.641383</td>
    </tr>
    <tr>
      <th>std</th>
      <td>131.832378</td>
      <td>11.038794</td>
    </tr>
    <tr>
      <th>min</th>
      <td>31.000000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>126.000000</td>
      <td>27.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>180.000000</td>
      <td>34.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>337.000000</td>
      <td>41.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>512.000000</td>
      <td>98.000000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="code.html" class="btn btn-neutral float-right" title="GPT2Summarizer (gpt2_summarizer.py)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, David Lorenzo Alfaro.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>